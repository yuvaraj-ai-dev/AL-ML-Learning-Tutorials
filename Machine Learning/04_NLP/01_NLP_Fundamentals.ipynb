{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. Natural Language Processing (NLP) Fundamentals\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves enabling machines to understand, interpret, and generate human language in a way that is valuable and meaningful.\n",
        "\n",
        "### What You'll Learn:\n",
        "- What is NLP and why it matters\n",
        "- Core NLP concepts and applications\n",
        "- NLP processing pipeline\n",
        "- Common Python libraries\n",
        "- Real-world examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Natural Language Processing (NLP)?\n",
        "\n",
        "NLP is a branch of **Artificial Intelligence (AI)** that focuses on enabling computers to:\n",
        "- **Understand** human language (both written and spoken)\n",
        "- **Process** and analyze text data\n",
        "- **Extract** meaningful information\n",
        "- **Generate** human-like responses\n",
        "\n",
        "### Real-World Examples:\n",
        "1. **Google Translate** - Translates text between languages\n",
        "2. **ChatGPT** - Understands questions and generates answers\n",
        "3. **Siri/Alexa** - Voice assistants that understand commands\n",
        "4. **Gmail Spam Filter** - Classifies emails as spam or not spam\n",
        "5. **Amazon Reviews** - Analyzes customer sentiment\n",
        "6. **Netflix** - Recommends movies based on descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why is NLP Important?\n",
        "\n",
        "- **Big Data Problem**: Companies have millions of text documents, emails, and reviews\n",
        "- **Business Value**: Extract insights, improve customer service, automate tasks\n",
        "- **Communication**: Bridge gap between human language and machine understanding\n",
        "- **Career Opportunity**: NLP skills are highly in-demand\n",
        "- **Innovation**: Powers modern AI applications (ChatGPT, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NLP Applications in Industry\n",
        "\n",
        "| Application | Industry | Example |\n",
        "|---|---|---|\n",
        "| **Sentiment Analysis** | Finance | Analyze stock market sentiment from news |\n",
        "| **Machine Translation** | Tech | Google Translate, real-time subtitles |\n",
        "| **Chatbots** | Customer Service | Customer support automation |\n",
        "| **Named Entity Recognition** | Healthcare | Extract patient names, diseases from medical records |\n",
        "| **Text Classification** | Media | Auto-tagging news articles |\n",
        "| **Question Answering** | Search | Google Search with direct answers |\n",
        "| **Resume Screening** | HR | Automated job application filtering |\n",
        "| **Content Summarization** | News | Auto-generate article summaries |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required NLP libraries...\n",
            "✓ nltk already installed\n",
            "✓ spacy already installed\n",
            "✓ textblob already installed\n",
            "✓ transformers already installed\n",
            "✓ torch already installed\n",
            "Installing scikit-learn...\n",
            "✓ scikit-learn installed\n",
            "✓ pandas already installed\n",
            "\n",
            "✅ All libraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Installing required NLP libraries...\")\n",
        "packages = ['nltk', 'spacy', 'textblob', 'transformers', 'torch', 'scikit-learn', 'pandas']\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"✓ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "        print(f\"✓ {package} installed\")\n",
        "\n",
        "print(\"\\n✅ All libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing required libraries...\n",
            "✓ NLTK version: 3.9.2\n",
            "✓ spaCy available\n",
            "✓ TextBlob available\n",
            "✓ Pandas and NumPy ready\n",
            "\n",
            "Downloading NLTK resources...\n",
            "✓ NLTK resources downloaded\n"
          ]
        }
      ],
      "source": [
        "# Import and verify libraries\n",
        "import nltk\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Importing required libraries...\")\n",
        "print(\"✓ NLTK version:\", nltk.__version__)\n",
        "print(\"✓ spaCy available\")\n",
        "print(\"✓ TextBlob available\")\n",
        "print(\"✓ Pandas and NumPy ready\")\n",
        "\n",
        "# Download NLTK data\n",
        "print(\"\\nDownloading NLTK resources...\")\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "print(\"✓ NLTK resources downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The NLP Processing Pipeline\n",
        "\n",
        "Every NLP task follows a similar pipeline:\n",
        "\n",
        "```\n",
        "Raw Text Input\n",
        "    ↓\n",
        "1. TEXT CLEANING (Remove noise, special characters)\n",
        "    ↓\n",
        "2. TOKENIZATION (Break into words/sentences)\n",
        "    ↓\n",
        "3. NORMALIZATION (Lowercase, remove stopwords)\n",
        "    ↓\n",
        "4. FEATURE EXTRACTION (Convert text to numbers)\n",
        "    ↓\n",
        "5. MODEL/ANALYSIS (Apply ML algorithm or analyze)\n",
        "    ↓\n",
        "Output/Results\n",
        "```\n",
        "\n",
        "### Example: Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXAMPLE: SENTIMENT ANALYSIS PIPELINE\n",
            "============================================================\n",
            "\n",
            "1. RAW TEXT INPUT:\n",
            "   'I absolutely love this product! It's amazing and works perfectly.'\n",
            "\n",
            "2. TEXT CLEANING & TOKENIZATION:\n",
            "   Cleaned: 'I absolutely love this product! It's amazing and works perfectly.'\n",
            "\n",
            "3. ANALYSIS:\n",
            "   Polarity (Sentiment): 0.74\n",
            "   Subjectivity: 0.83\n",
            "\n",
            "4. INTERPRETATION:\n",
            "   ✓ POSITIVE sentiment detected\n"
          ]
        }
      ],
      "source": [
        "# Example: Simple Sentiment Analysis Pipeline\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Step 1: Raw text input\n",
        "raw_text = \"I absolutely love this product! It's amazing and works perfectly.\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"EXAMPLE: SENTIMENT ANALYSIS PIPELINE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n1. RAW TEXT INPUT:\")\n",
        "print(f\"   '{raw_text}'\")\n",
        "\n",
        "# Step 2: Create TextBlob object\n",
        "blob = TextBlob(raw_text)\n",
        "\n",
        "print(f\"\\n2. TEXT CLEANING & TOKENIZATION:\")\n",
        "print(f\"   Cleaned: '{blob}'\")\n",
        "#print(f\"   Words: {blob.words}\")\n",
        "\n",
        "print(f\"\\n3. ANALYSIS:\")\n",
        "print(f\"   Polarity (Sentiment): {blob.sentiment.polarity:.2f}\")\n",
        "print(f\"   Subjectivity: {blob.sentiment.subjectivity:.2f}\")\n",
        "\n",
        "print(f\"\\n4. INTERPRETATION:\")\n",
        "if blob.sentiment.polarity > 0.5:\n",
        "    print(f\"   ✓ POSITIVE sentiment detected\")\n",
        "else:\n",
        "    print(f\"   ✗ NEGATIVE sentiment detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key NLP Concepts\n",
        "\n",
        "### 1. **Tokens**\n",
        "- Individual words or sentences\n",
        "- \"Hello world\" → [\"Hello\", \"world\"]\n",
        "\n",
        "### 2. **Lemmatization**\n",
        "- Convert words to base form\n",
        "- \"running\", \"runs\", \"ran\" → \"run\"\n",
        "\n",
        "### 3. **Stopwords**\n",
        "- Common words with little meaning\n",
        "- \"a\", \"the\", \"is\", \"and\"\n",
        "\n",
        "### 4. **Part of Speech (POS)**\n",
        "- Identify word types\n",
        "- \"Hello\" = Noun, \"world\" = Noun\n",
        "\n",
        "### 5. **Named Entities**\n",
        "- Proper nouns and important terms\n",
        "- People, places, organizations\n",
        "\n",
        "### 6. **Embeddings**\n",
        "- Convert words to numerical vectors\n",
        "- Capture semantic meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "KEY NLP CONCEPTS DEMONSTRATION\n",
            "============================================================\n",
            "\n",
            "1. TOKENIZATION:\n",
            "   Original: The quick brown foxes were running through the beautiful forest.\n",
            "   Tokens: ['The', 'quick', 'brown', 'foxes', 'were', 'running', 'through', 'the', 'beautiful', 'forest', '.']\n",
            "\n",
            "2. STOPWORDS REMOVAL:\n",
            "   Before: 11 words\n",
            "   After: 7 words\n",
            "   Meaningful words: ['quick', 'brown', 'foxes', 'running', 'beautiful', 'forest', '.']\n",
            "\n",
            "3. LEMMATIZATION (Convert to base form):\n",
            "   running → running\n",
            "   foxes → fox\n",
            "   beautiful → beautiful\n"
          ]
        }
      ],
      "source": [
        "# Demonstration of key NLP concepts\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"KEY NLP CONCEPTS DEMONSTRATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "text = \"The quick brown foxes were running through the beautiful forest.\"\n",
        "\n",
        "# 1. Tokenization\n",
        "print(\"\\n1. TOKENIZATION:\")\n",
        "print(f\"   Original: {text}\")\n",
        "words = word_tokenize(text)\n",
        "print(f\"   Tokens: {words}\")\n",
        "\n",
        "# 2. Stopwords removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(f\"\\n2. STOPWORDS REMOVAL:\")\n",
        "print(f\"   Before: {len(words)} words\")\n",
        "print(f\"   After: {len(filtered_words)} words\")\n",
        "print(f\"   Meaningful words: {filtered_words}\")\n",
        "\n",
        "# 3. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(f\"\\n3. LEMMATIZATION (Convert to base form):\")\n",
        "for word in [\"running\", \"foxes\", \"beautiful\"]:\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(f\"   {word} → {lemma}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common NLP Libraries\n",
        "\n",
        "### 1. **NLTK (Natural Language Toolkit)**\n",
        "- Most popular Python NLP library\n",
        "- Good for beginners\n",
        "- Tokenization, stemming, POS tagging\n",
        "\n",
        "### 2. **spaCy**\n",
        "- Industrial-strength NLP\n",
        "- Fast and efficient\n",
        "- Named Entity Recognition, dependency parsing\n",
        "\n",
        "### 3. **TextBlob**\n",
        "- Simple and intuitive API\n",
        "- Sentiment analysis, translation\n",
        "- Good for beginners\n",
        "\n",
        "### 4. **Transformers (Hugging Face)**\n",
        "- State-of-the-art models\n",
        "- BERT, GPT, etc.\n",
        "- Deep learning for NLP\n",
        "\n",
        "### 5. **scikit-learn**\n",
        "- Machine learning algorithms\n",
        "- Text classification, clustering\n",
        "- Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPARING NLP LIBRARIES\n",
            "============================================================\n",
            "\n",
            "1. NLTK - Basic Tokenization:\n",
            "   Tokens: ['Apple', 'is', 'looking', 'at', 'buying', 'UK', 'startup', 'for', '$', '1', 'billion', '.']\n",
            "\n",
            "2. TextBlob - Sentiment & Noun Phrases:\n",
            "   Noun Phrases: ['apple', 'uk']\n",
            "   Sentiment: 0.00\n",
            "\n",
            "3. spaCy - Named Entity Recognition:\n",
            "\n",
            "3. spaCy - (model not loaded yet)\n",
            "\n",
            "✓ Each library has different strengths!\n"
          ]
        }
      ],
      "source": [
        "# Quick comparison of libraries\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARING NLP LIBRARIES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "text = \"Apple is looking at buying UK startup for $1 billion.\"\n",
        "\n",
        "# 1. NLTK\n",
        "print(\"\\n1. NLTK - Basic Tokenization:\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(f\"   Tokens: {word_tokenize(text)}\")\n",
        "\n",
        "# 2. TextBlob\n",
        "print(\"\\n2. TextBlob - Sentiment & Noun Phrases:\")\n",
        "from textblob import TextBlob\n",
        "blob = TextBlob(text)\n",
        "print(f\"   Noun Phrases: {blob.noun_phrases}\")\n",
        "print(f\"   Sentiment: {blob.sentiment.polarity:.2f}\")\n",
        "\n",
        "# 3. spaCy (if available)\n",
        "try:\n",
        "    import spacy\n",
        "    print(\"\\n3. spaCy - Named Entity Recognition:\")\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(text)\n",
        "    print(f\"   Named Entities: {[(ent.text, ent.label_) for ent in doc.ents]}\")\n",
        "except:\n",
        "    print(\"\\n3. spaCy - (model not loaded yet)\")\n",
        "\n",
        "print(\"\\n✓ Each library has different strengths!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
