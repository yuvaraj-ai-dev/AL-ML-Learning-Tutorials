{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. Natural Language Processing (NLP) Fundamentals",
        "",
        "## Course Level: Beginner \u2b50",
        "",
        "### What You'll Learn:",
        "- What is NLP and why it matters",
        "- Core NLP concepts and applications",
        "- NLP processing pipeline",
        "- Common Python libraries",
        "- Real-world examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Natural Language Processing (NLP)?",
        "",
        "NLP is a branch of **Artificial Intelligence (AI)** that focuses on enabling computers to:",
        "- **Understand** human language (both written and spoken)",
        "- **Process** and analyze text data",
        "- **Extract** meaningful information",
        "- **Generate** human-like responses",
        "",
        "### Real-World Examples:",
        "1. **Google Translate** - Translates text between languages",
        "2. **ChatGPT** - Understands questions and generates answers",
        "3. **Siri/Alexa** - Voice assistants that understand commands",
        "4. **Gmail Spam Filter** - Classifies emails as spam or not spam",
        "5. **Amazon Reviews** - Analyzes customer sentiment",
        "6. **Netflix** - Recommends movies based on descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why is NLP Important?",
        "",
        "- **Big Data Problem**: Companies have millions of text documents, emails, and reviews",
        "- **Business Value**: Extract insights, improve customer service, automate tasks",
        "- **Communication**: Bridge gap between human language and machine understanding",
        "- **Career Opportunity**: NLP skills are highly in-demand",
        "- **Innovation**: Powers modern AI applications (ChatGPT, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NLP Applications in Industry",
        "",
        "| Application | Industry | Example |",
        "|---|---|---|",
        "| **Sentiment Analysis** | Finance | Analyze stock market sentiment from news |",
        "| **Machine Translation** | Tech | Google Translate, real-time subtitles |",
        "| **Chatbots** | Customer Service | Customer support automation |",
        "| **Named Entity Recognition** | Healthcare | Extract patient names, diseases from medical records |",
        "| **Text Classification** | Media | Auto-tagging news articles |",
        "| **Question Answering** | Search | Google Search with direct answers |",
        "| **Resume Screening** | HR | Automated job application filtering |",
        "| **Content Summarization** | News | Auto-generate article summaries |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries",
        "import subprocess",
        "import sys",
        "",
        "print(\"Installing required NLP libraries...\")",
        "packages = ['nltk', 'spacy', 'textblob', 'transformers', 'torch', 'scikit-learn', 'pandas']",
        "",
        "for package in packages:",
        "    try:",
        "        __import__(package)",
        "        print(f\"\u2713 {package} already installed\")",
        "    except ImportError:",
        "        print(f\"Installing {package}...\")",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])",
        "        print(f\"\u2713 {package} installed\")",
        "",
        "print(\"\\n\u2705 All libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and verify libraries",
        "import nltk",
        "import spacy",
        "from textblob import TextBlob",
        "import pandas as pd",
        "import numpy as np",
        "",
        "print(\"Importing required libraries...\")",
        "print(\"\u2713 NLTK version:\", nltk.__version__)",
        "print(\"\u2713 spaCy available\")",
        "print(\"\u2713 TextBlob available\")",
        "print(\"\u2713 Pandas and NumPy ready\")",
        "",
        "# Download NLTK data",
        "print(\"\\nDownloading NLTK resources...\")",
        "nltk.download('punkt', quiet=True)",
        "nltk.download('averaged_perceptron_tagger', quiet=True)",
        "nltk.download('wordnet', quiet=True)",
        "nltk.download('stopwords', quiet=True)",
        "print(\"\u2713 NLTK resources downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The NLP Processing Pipeline",
        "",
        "Every NLP task follows a similar pipeline:",
        "",
        "```",
        "Raw Text Input",
        "    \u2193",
        "1. TEXT CLEANING (Remove noise, special characters)",
        "    \u2193",
        "2. TOKENIZATION (Break into words/sentences)",
        "    \u2193",
        "3. NORMALIZATION (Lowercase, remove stopwords)",
        "    \u2193",
        "4. FEATURE EXTRACTION (Convert text to numbers)",
        "    \u2193",
        "5. MODEL/ANALYSIS (Apply ML algorithm or analyze)",
        "    \u2193",
        "Output/Results",
        "```",
        "",
        "### Example: Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Simple Sentiment Analysis Pipeline",
        "from textblob import TextBlob",
        "",
        "# Step 1: Raw text input",
        "raw_text = \"I absolutely love this product! It's amazing and works perfectly.\"",
        "",
        "print(\"=\" * 60)",
        "print(\"EXAMPLE: SENTIMENT ANALYSIS PIPELINE\")",
        "print(\"=\" * 60)",
        "",
        "print(f\"\\n1. RAW TEXT INPUT:\")",
        "print(f\"   '{raw_text}'\")",
        "",
        "# Step 2: Create TextBlob object",
        "blob = TextBlob(raw_text)",
        "",
        "print(f\"\\n2. TEXT CLEANING & TOKENIZATION:\")",
        "print(f\"   Cleaned: '{blob}'\")",
        "print(f\"   Words: {blob.words}\")",
        "",
        "print(f\"\\n3. ANALYSIS:\")",
        "print(f\"   Polarity (Sentiment): {blob.sentiment.polarity:.2f}\")",
        "print(f\"   Subjectivity: {blob.sentiment.subjectivity:.2f}\")",
        "",
        "print(f\"\\n4. INTERPRETATION:\")",
        "if blob.sentiment.polarity > 0.5:",
        "    print(f\"   \u2713 POSITIVE sentiment detected\")",
        "else:",
        "    print(f\"   \u2717 NEGATIVE sentiment detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key NLP Concepts",
        "",
        "### 1. **Tokens**",
        "- Individual words or sentences",
        "- \"Hello world\" \u2192 [\"Hello\", \"world\"]",
        "",
        "### 2. **Lemmatization**",
        "- Convert words to base form",
        "- \"running\", \"runs\", \"ran\" \u2192 \"run\"",
        "",
        "### 3. **Stopwords**",
        "- Common words with little meaning",
        "- \"a\", \"the\", \"is\", \"and\"",
        "",
        "### 4. **Part of Speech (POS)**",
        "- Identify word types",
        "- \"Hello\" = Noun, \"world\" = Noun",
        "",
        "### 5. **Named Entities**",
        "- Proper nouns and important terms",
        "- People, places, organizations",
        "",
        "### 6. **Embeddings**",
        "- Convert words to numerical vectors",
        "- Capture semantic meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstration of key NLP concepts",
        "",
        "from nltk.tokenize import word_tokenize, sent_tokenize",
        "from nltk.corpus import stopwords",
        "from nltk.stem import WordNetLemmatizer",
        "",
        "print(\"=\" * 60)",
        "print(\"KEY NLP CONCEPTS DEMONSTRATION\")",
        "print(\"=\" * 60)",
        "",
        "text = \"The quick brown foxes were running through the beautiful forest.\"",
        "",
        "# 1. Tokenization",
        "print(\"\\n1. TOKENIZATION:\")",
        "print(f\"   Original: {text}\")",
        "words = word_tokenize(text)",
        "print(f\"   Tokens: {words}\")",
        "",
        "# 2. Stopwords removal",
        "stop_words = set(stopwords.words('english'))",
        "filtered_words = [word for word in words if word.lower() not in stop_words]",
        "print(f\"\\n2. STOPWORDS REMOVAL:\")",
        "print(f\"   Before: {len(words)} words\")",
        "print(f\"   After: {len(filtered_words)} words\")",
        "print(f\"   Meaningful words: {filtered_words}\")",
        "",
        "# 3. Lemmatization",
        "lemmatizer = WordNetLemmatizer()",
        "print(f\"\\n3. LEMMATIZATION (Convert to base form):\")",
        "for word in [\"running\", \"foxes\", \"beautiful\"]:",
        "    lemma = lemmatizer.lemmatize(word)",
        "    print(f\"   {word} \u2192 {lemma}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common NLP Libraries",
        "",
        "### 1. **NLTK (Natural Language Toolkit)**",
        "- Most popular Python NLP library",
        "- Good for beginners",
        "- Tokenization, stemming, POS tagging",
        "",
        "### 2. **spaCy**",
        "- Industrial-strength NLP",
        "- Fast and efficient",
        "- Named Entity Recognition, dependency parsing",
        "",
        "### 3. **TextBlob**",
        "- Simple and intuitive API",
        "- Sentiment analysis, translation",
        "- Good for beginners",
        "",
        "### 4. **Transformers (Hugging Face)**",
        "- State-of-the-art models",
        "- BERT, GPT, etc.",
        "- Deep learning for NLP",
        "",
        "### 5. **scikit-learn**",
        "- Machine learning algorithms",
        "- Text classification, clustering",
        "- Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick comparison of libraries",
        "",
        "print(\"=\" * 60)",
        "print(\"COMPARING NLP LIBRARIES\")",
        "print(\"=\" * 60)",
        "",
        "text = \"Apple is looking at buying UK startup for $1 billion.\"",
        "",
        "# 1. NLTK",
        "print(\"\\n1. NLTK - Basic Tokenization:\")",
        "from nltk.tokenize import word_tokenize",
        "print(f\"   Tokens: {word_tokenize(text)}\")",
        "",
        "# 2. TextBlob",
        "print(\"\\n2. TextBlob - Sentiment & Noun Phrases:\")",
        "from textblob import TextBlob",
        "blob = TextBlob(text)",
        "print(f\"   Noun Phrases: {blob.noun_phrases}\")",
        "print(f\"   Sentiment: {blob.sentiment.polarity:.2f}\")",
        "",
        "# 3. spaCy (if available)",
        "try:",
        "    import spacy",
        "    print(\"\\n3. spaCy - Named Entity Recognition:\")",
        "    nlp = spacy.load('en_core_web_sm')",
        "    doc = nlp(text)",
        "    print(f\"   Named Entities: {[(ent.text, ent.label_) for ent in doc.ents]}\")",
        "except:",
        "    print(\"\\n3. spaCy - (model not loaded yet)\")",
        "",
        "print(\"\\n\u2713 Each library has different strengths!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}