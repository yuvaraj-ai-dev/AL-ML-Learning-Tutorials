{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. Question Answering Systems\n",
        "Question Answering (QA) systems are advanced applications in Natural Language Processing (NLP) that aim to automatically answer questions posed by users in natural language. These systems leverage various techniques, including information retrieval, machine learning, and deep learning, to understand the context of the question and provide accurate and relevant answers from a given dataset or knowledge base.\n",
        "\n",
        "### What You'll Learn:\n",
        "- How QA systems work\n",
        "- BERT for QA\n",
        "- Building QA pipeline\n",
        "- Evaluation\n",
        "- Real applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QA System Architecture\n",
        "\n",
        "```\n",
        "Question Input\n",
        "    ↓\n",
        "Context Retrieval (Find relevant documents)\n",
        "    ↓\n",
        "Passage Ranking (Find best passages)\n",
        "    ↓\n",
        "Answer Extraction (Find answer span)\n",
        "    ↓\n",
        "Answer Output\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BERT-based QA\n",
        "\n",
        "**Task**: Given context and question, find answer span\n",
        "\n",
        "**Process**:\n",
        "1. Tokenize question and context\n",
        "2. Encode with BERT\n",
        "3. Output: Start and end positions of answer\n",
        "\n",
        "**Advantages**:\n",
        "- Pre-trained on massive text\n",
        "- Contextual understanding\n",
        "- High accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "QUESTION ANSWERING WITH BERT\n",
            "============================================================\n",
            "(Example requires transformers library)\n",
            "\n",
            "BERT QA Process:\n",
            "1. Load pre-trained model on SQuAD dataset\n",
            "2. Tokenize question and context together\n",
            "3. Get logits for token positions\n",
            "4. Extract answer span with highest score\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "print('='*60)\n",
        "print('QUESTION ANSWERING WITH BERT')\n",
        "print('='*60)\n",
        "\n",
        "try:\n",
        "    qa_pipeline = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
        "    \n",
        "    context = '''Natural Language Processing (NLP) is a subfield of linguistics, computer science, \n",
        "    and artificial intelligence concerned with the interactions between computers and human language. \n",
        "    NLP is used to apply machine learning algorithms to text and speech. \n",
        "    Some examples include sentiment analysis, topic modeling, and machine translation.'''\n",
        "    \n",
        "    questions = [\n",
        "        'What is NLP?',\n",
        "        'What are applications of NLP?',\n",
        "        'Which field does NLP belong to?'\n",
        "    ]\n",
        "    \n",
        "    print(f'\\nContext:\\n{context}\\n')\n",
        "    print('='*60)\n",
        "    \n",
        "    for question in questions:\n",
        "        result = qa_pipeline(question=question, context=context)\n",
        "        print(f'\\nQ: {question}')\n",
        "        print(f'A: {result[\"answer\"]}')\n",
        "        print(f'   Confidence: {result[\"score\"]:.2%}')\n",
        "        \n",
        "except Exception as e:\n",
        "    print('(Example requires transformers library)')\n",
        "    print('\\nBERT QA Process:')\n",
        "    print('1. Load pre-trained model on SQuAD dataset')\n",
        "    print('2. Tokenize question and context together')\n",
        "    print('3. Get logits for token positions')\n",
        "    print('4. Extract answer span with highest score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building QA System Components\n",
        "\n",
        "### 1. Question Understanding\n",
        "- Identify question type\n",
        "- Extract keywords\n",
        "- Determine answer type (person, place, date, etc.)\n",
        "\n",
        "### 2. Document Retrieval\n",
        "- Find relevant documents\n",
        "- Score by relevance\n",
        "- Return top candidates\n",
        "\n",
        "### 3. Passage Selection\n",
        "- Identify relevant passages\n",
        "- Rank passages\n",
        "- Select best passage\n",
        "\n",
        "### 4. Answer Extraction\n",
        "- Use NER or span extraction\n",
        "- Generate answer\n",
        "- Score confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "FULL QA SYSTEM EXAMPLE\n",
            "============================================================\n",
            "\n",
            "Step 1: Question Understanding\n",
            "  Question: When was machine learning invented?\n",
            "  Question Type: When (temporal)\n",
            "  Expected Answer: Date\n",
            "\n",
            "Step 2: Document Retrieval\n",
            "  Retrieved documents (top 2):\n",
            "    - history_of_ml.pdf: 95%\n",
            "    - ai_overview.pdf: 87%\n",
            "\n",
            "Step 3: Passage Selection\n",
            "  Best passage: \"ML emerged in 1956 at Dartmouth Conference\"\n",
            "\n",
            "Step 4: Answer Extraction\n",
            "  Answer: 1956\n",
            "  Confidence: 92%\n",
            "\n",
            "Final Answer: 1956\n"
          ]
        }
      ],
      "source": [
        "print('\\nFULL QA SYSTEM EXAMPLE')\n",
        "print('='*60)\n",
        "\n",
        "print('\\nStep 1: Question Understanding')\n",
        "question = 'When was machine learning invented?'\n",
        "print(f'  Question: {question}')\n",
        "print(f'  Question Type: When (temporal)')\n",
        "print(f'  Expected Answer: Date')\n",
        "\n",
        "print('\\nStep 2: Document Retrieval')\n",
        "documents = [\n",
        "    ('history_of_ml.pdf', 0.95),\n",
        "    ('ai_overview.pdf', 0.87),\n",
        "    ('neural_networks.pdf', 0.62)\n",
        "]\n",
        "print(f'  Retrieved documents (top 2):')\n",
        "for doc, score in documents[:2]:\n",
        "    print(f'    - {doc}: {score:.0%}')\n",
        "\n",
        "print('\\nStep 3: Passage Selection')\n",
        "print('  Best passage: \"ML emerged in 1956 at Dartmouth Conference\"')\n",
        "\n",
        "print('\\nStep 4: Answer Extraction')\n",
        "print('  Answer: 1956')\n",
        "print('  Confidence: 92%')\n",
        "\n",
        "print('\\nFinal Answer: 1956')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "### EM (Exact Match)\n",
        "- Answer exactly matches reference\n",
        "- Either 0 or 1\n",
        "\n",
        "### F1 Score\n",
        "- Overlap between predicted and reference\n",
        "- Accounts for partial matches\n",
        "\n",
        "### Example:\n",
        "- Reference: 'Paris, France'\n",
        "- Predicted: 'Paris'\n",
        "- EM: 0 (doesn't match exactly)\n",
        "- F1: 0.67 (partial match)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
