{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [1. Title and Overview](#1-title-and-overview)\n",
    "- [2. Setup and Imports](#2-setup-and-imports)\n",
    "- [3. Section 1: Introduction to Pointwise Operations](#3-section-1-introduction-to-pointwise-operations)\n",
    "  - [What are Pointwise Operations?](#what-are-pointwise-operations)\n",
    "  - [Why Pointwise Operations Matter](#why-pointwise-operations-matter)\n",
    "  - [Basic Concepts](#basic-concepts)\n",
    "- [4. Section 2: Brightness and Contrast Adjustments](#4-section-2-brightness-and-contrast-adjustments)\n",
    "  - [Understanding Brightness and Contrast](#understanding-brightness-and-contrast)\n",
    "  - [Adjusting Brightness](#adjusting-brightness)\n",
    "  - [Adjusting Contrast](#adjusting-contrast)\n",
    "  - [Combined Brightness and Contrast](#combined-brightness-and-contrast)\n",
    "- [5. Section 3: Introduction to Histograms](#5-section-3-introduction-to-histograms)\n",
    "  - [What is a Histogram?](#what-is-a-histogram)\n",
    "  - [Computing and Plotting Histograms](#computing-and-plotting-histograms)\n",
    "  - [Histograms for Color Images](#histograms-for-color-images)\n",
    "  - [Interpreting Histograms](#interpreting-histograms)\n",
    "- [6. Section 4: Histogram Equalization - Grayscale](#6-section-4-histogram-equalization---grayscale)\n",
    "  - [What is Histogram Equalization?](#what-is-histogram-equalization)\n",
    "  - [How It Works](#how-it-works)\n",
    "  - [Implementing Grayscale Equalization](#implementing-grayscale-equalization)\n",
    "  - [When to Use and Limitations](#when-to-use-and-limitations)\n",
    "- [7. Section 5: Histogram Equalization - Color Images](#7-section-5-histogram-equalization---color-images)\n",
    "  - [Challenges with Color Equalization](#challenges-with-color-equalization)\n",
    "  - [Equalization in HSV Space](#equalization-in-hsv-space)\n",
    "  - [Equalization in YCbCr Space](#equalization-in-ycbcr-space)\n",
    "  - [RGB Equalization (with Caveats)](#rgb-equalization-with-caveats)\n",
    "- [8. Section 6: Contrast Limited Adaptive Histogram Equalization (CLAHE)](#8-section-6-contrast-limited-adaptive-histogram-equalization-clahe)\n",
    "  - [What is CLAHE?](#what-is-clahe)\n",
    "  - [Parameters Explained](#parameters-explained)\n",
    "  - [Implementing CLAHE](#implementing-clahe)\n",
    "  - [When CLAHE Shines](#when-clahe-shines)\n",
    "- [9. Section 7: Gamma Correction](#9-section-7-gamma-correction)\n",
    "  - [What is Gamma Correction?](#what-is-gamma-correction)\n",
    "  - [Understanding Gamma Values](#understanding-gamma-values)\n",
    "  - [Implementing Gamma Correction](#implementing-gamma-correction)\n",
    "  - [Practical Applications](#practical-applications)\n",
    "- [10. Section 8: Putting It All Together](#10-section-8-putting-it-all-together)\n",
    "  - [Comparison of Techniques](#comparison-of-techniques)\n",
    "  - [Best Practices and Tips](#best-practices-and-tips)\n",
    "  - [Further Reading and Exercises](#further-reading-and-exercises)\n",
    "- [11. Conclusion](#11-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Title and Overview\n",
    "\n",
    "# Pointwise Operations and Histograms: Enhancing Images Pixel by Pixel\n",
    "\n",
    "**Brief Introduction**: A beginner-friendly guide to pointwise operations, brightness/contrast adjustments, histograms, and advanced equalization techniques in image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup and Imports\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "This section explains the necessary libraries we'll use for image processing tasks.\n",
    "\n",
    "- **OpenCV**: Our main toolbox for image operations.\n",
    "- **NumPy**: For numerical computations.\n",
    "- **Matplotlib**: For visualizations.\n",
    "- **scikit-image**: For advanced functions like CLAHE.\n",
    "\n",
    "**Beginner Tip**: \"Think of libraries as toolboxes. OpenCV is our main toolbox for image operations, NumPy for numerical computations, Matplotlib for visualizations, and scikit-image for advanced functions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "\n",
    "# Set up matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Introduction to Pointwise Operations\n",
    "\n",
    "## What are Pointwise Operations?\n",
    "\n",
    "Pointwise operations modify each pixel independently, like adjusting brightness or contrast. Analogy: \"It's like turning up the volume on each note in a song individually.\"\n",
    "\n",
    "These operations are foundational for image enhancement and preprocessing for computer vision tasks.\n",
    "\n",
    "## Why Pointwise Operations Matter\n",
    "\n",
    "Pointwise operations enhance visibility in low-light images, correct camera issues, and prepare data for analysis. Common use cases include photography editing, medical imaging, and surveillance.\n",
    "\n",
    "## Basic Concepts\n",
    "\n",
    "Pixel values range from 0-255 for 8-bit images, representing intensity transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display a sample image\n",
    "img = cv2.imread('datasets/sample_images/sample1.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Sample Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Brightness and Contrast Adjustments\n",
    "\n",
    "## Understanding Brightness and Contrast\n",
    "\n",
    "- **Brightness**: Overall lightness/darkness. Analogy: \"Brightness is like room lighting; contrast is like the range of shades in a painting.\"\n",
    "- **Contrast**: Difference between light and dark areas.\n",
    "\n",
    "Mathematical formulas involve brightness shift and contrast scaling.\n",
    "\n",
    "## Adjusting Brightness\n",
    "\n",
    "Add or subtract a constant from all pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image\n",
    "img_dark = cv2.imread('datasets/sample_images/sample2.png')\n",
    "img_dark_rgb = cv2.cvtColor(img_dark, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Increase brightness\n",
    "bright_img = cv2.add(img_dark, 50)\n",
    "bright_img_rgb = cv2.cvtColor(bright_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Decrease brightness\n",
    "dark_img = cv2.subtract(img_dark, 50)\n",
    "dark_img_rgb = cv2.cvtColor(dark_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display side-by-side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(img_dark_rgb)\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(bright_img_rgb)\n",
    "axes[1].set_title('Brighter')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(dark_img_rgb)\n",
    "axes[2].set_title('Darker')\n",
    "axes[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with a bright image\n",
    "img_bright = cv2.imread('datasets/sample_images/group.jpg')\n",
    "img_bright_rgb = cv2.cvtColor(img_bright, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Decrease brightness\n",
    "dim_img = cv2.subtract(img_bright, 30)\n",
    "dim_img_rgb = cv2.cvtColor(dim_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_bright_rgb)\n",
    "plt.title('Original Bright Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dim_img_rgb)\n",
    "plt.title('Dimmed Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Contrast\n",
    "\n",
    "Multiply pixels by a factor, possibly with offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase contrast on a low-contrast image\n",
    "img_low_contrast = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to float for multiplication\n",
    "img_float = img_low_contrast.astype(np.float32)\n",
    "contrast_img = cv2.multiply(img_float, 1.5)\n",
    "contrast_img = np.clip(contrast_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_low_contrast, cmap='gray')\n",
    "plt.title('Original Low Contrast')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(contrast_img, cmap='gray')\n",
    "plt.title('Increased Contrast')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease contrast on a high-contrast image\n",
    "img_high_contrast = cv2.imread('datasets/sample_images/coins.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_float = img_high_contrast.astype(np.float32)\n",
    "low_contrast_img = cv2.multiply(img_float, 0.5)\n",
    "low_contrast_img = np.clip(low_contrast_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_high_contrast, cmap='gray')\n",
    "plt.title('Original High Contrast')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(low_contrast_img, cmap='gray')\n",
    "plt.title('Decreased Contrast')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Beginner Tip: Don't overdo contrast - it can make images look unnatural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Brightness and Contrast\n",
    "\n",
    "Formula: `new_pixel = alpha * old_pixel + beta`\n",
    "\n",
    "Common Mistake: \"Forgetting to clip values to 0-255 range can cause overflow/underflow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined adjustment\n",
    "img = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "alpha = 1.2  # contrast\n",
    "beta = 30    # brightness\n",
    "\n",
    "adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(adjusted, cmap='gray')\n",
    "plt.title(f'Adjusted (alpha={alpha}, beta={beta})')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Introduction to Histograms\n",
    "\n",
    "## What is a Histogram?\n",
    "\n",
    "A histogram shows the distribution of pixel intensities. Analogy: \"Like a bar graph of grades in a class - shows how many pixels are at each brightness level.\"\n",
    "\n",
    "X-axis: Intensity (0-255), Y-axis: Frequency.\n",
    "\n",
    "## Computing and Plotting Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute histogram for grayscale image\n",
    "img_gray = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.title('Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist)\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Beginner Tip: Histograms help you understand image characteristics at a glance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms for Color Images\n",
    "\n",
    "Separate histograms for R, G, B channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB histograms\n",
    "img_color = cv2.imread('datasets/sample_images/group.jpg')\n",
    "img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Calculate histograms for each channel\n",
    "hist_r = cv2.calcHist([img_color], [0], None, [256], [0, 256])\n",
    "hist_g = cv2.calcHist([img_color], [1], None, [256], [0, 256])\n",
    "hist_b = cv2.calcHist([img_color], [2], None, [256], [0, 256])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(img_color_rgb)\n",
    "plt.title('Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.plot(hist_r, color='red')\n",
    "plt.title('Red Channel')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.plot(hist_g, color='green')\n",
    "plt.title('Green Channel')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.plot(hist_b, color='blue')\n",
    "plt.title('Blue Channel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Histograms\n",
    "\n",
    "- Low contrast: Narrow histogram.\n",
    "- High contrast: Wide histogram.\n",
    "- Dark images: Left-skewed.\n",
    "- Bright images: Right-skewed.\n",
    "\n",
    "Tip: \"A well-balanced histogram spreads across the range for good contrast.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Histogram Equalization - Grayscale\n",
    "\n",
    "## What is Histogram Equalization?\n",
    "\n",
    "Redistributes pixel intensities to improve contrast. Analogy: \"Like evening out wealth in an economy - spreads out the brightness levels.\"\n",
    "\n",
    "Goal: Transform histogram to be uniform (flat).\n",
    "\n",
    "## How It Works\n",
    "\n",
    "Uses cumulative distribution function (CDF) to map intensities to new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing Grayscale Equalization\n",
    "\n",
    "img = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute histograms before equalization\n",
    "hist_before = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "\n",
    "# Equalize\n",
    "img_eq = cv2.equalizeHist(img)\n",
    "\n",
    "# Histogram after\n",
    "hist_after = cv2.calcHist([img_eq], [0], None, [256], [0, 256])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(img_eq, cmap='gray')\n",
    "plt.title('Equalized Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(hist_before, color='blue')\n",
    "plt.title('Histogram Before')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(hist_after, color='red')\n",
    "plt.title('Histogram After')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with coins.png\n",
    "img_coins = cv2.imread('datasets/sample_images/coins.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "hist_before_coins = cv2.calcHist([img_coins], [0], None, [256], [0, 256])\n",
    "img_coins_eq = cv2.equalizeHist(img_coins)\n",
    "hist_after_coins = cv2.calcHist([img_coins_eq], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(img_coins, cmap='gray')\n",
    "plt.title('Original Coins')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(img_coins_eq, cmap='gray')\n",
    "plt.title('Equalized Coins')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.plot(hist_before_coins)\n",
    "plt.title('Hist Before')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.plot(hist_after_coins)\n",
    "plt.title('Hist After')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use and Limitations\n",
    "\n",
    "Great for low-contrast images, but can amplify noise.\n",
    "\n",
    "Common Mistake: \"Applying to already high-contrast images can make them look unnatural.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Histogram Equalization - Color Images\n",
    "\n",
    "## Challenges with Color Equalization\n",
    "\n",
    "Equalizing RGB separately can cause color shifts. Use HSV or YCbCr color spaces.\n",
    "\n",
    "## Equalization in HSV Space\n",
    "\n",
    "Convert to HSV, equalize V channel, convert back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV equalization\n",
    "img_color = cv2.imread('datasets/sample_images/group.jpg')\n",
    "img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert to HSV\n",
    "hsv = cv2.cvtColor(img_color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Equalize V channel\n",
    "hsv[:, :, 2] = cv2.equalizeHist(hsv[:, :, 2])\n",
    "\n",
    "# Convert back to BGR\n",
    "img_hsv_eq = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "img_hsv_eq_rgb = cv2.cvtColor(img_hsv_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color_rgb)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_hsv_eq_rgb)\n",
    "plt.title('HSV Equalized')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalization in YCbCr Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YCbCr equalization\n",
    "img_color = cv2.imread('datasets/sample_images/group.jpg')\n",
    "img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert to YCbCr\n",
    "ycrcb = cv2.cvtColor(img_color, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "# Equalize Y channel\n",
    "ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "\n",
    "# Convert back\n",
    "img_ycrcb_eq = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "img_ycrcb_eq_rgb = cv2.cvtColor(img_ycrcb_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_color_rgb)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_hsv_eq_rgb)\n",
    "plt.title('HSV Equalized')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_ycrcb_eq_rgb)\n",
    "plt.title('YCbCr Equalized')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Equalization (with Caveats)\n",
    "\n",
    "Equalize each channel separately, but check color balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB equalization\n",
    "img_color = cv2.imread('datasets/sample_images/group.jpg')\n",
    "img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Equalize each channel\n",
    "b, g, r = cv2.split(img_color)\n",
    "b_eq = cv2.equalizeHist(b)\n",
    "g_eq = cv2.equalizeHist(g)\n",
    "r_eq = cv2.equalizeHist(r)\n",
    "\n",
    "# Merge back\n",
    "img_rgb_eq = cv2.merge([b_eq, g_eq, r_eq])\n",
    "img_rgb_eq_rgb = cv2.cvtColor(img_rgb_eq, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color_rgb)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_rgb_eq_rgb)\n",
    "plt.title('RGB Equalized (Note color shift)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Tip: Always check color balance after equalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
    "\n",
    "## What is CLAHE?\n",
    "\n",
    "Adaptive equalization on small regions (tiles) with contrast limiting to prevent noise amplification.\n",
    "\n",
    "## Parameters Explained\n",
    "\n",
    "- **Clip limit**: Maximum contrast enhancement.\n",
    "- **Tile size**: Size of regions.\n",
    "\n",
    "Beginner Tip: \"Think of it as local equalization - adjusts contrast in neighborhoods.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing CLAHE\n",
    "\n",
    "img = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Apply CLAHE\n",
    "img_clahe = clahe.apply(img)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_clahe, cmap='gray')\n",
    "plt.title('CLAHE')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.equalizeHist(img), cmap='gray')\n",
    "plt.title('Global Equalization')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with noisy image\n",
    "img_noisy = cv2.imread('datasets/sample_images/noisy_sp.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# CLAHE on noisy image\n",
    "clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
    "img_noisy_clahe = clahe.apply(img_noisy)\n",
    "\n",
    "# Global equalization for comparison\n",
    "img_noisy_global = cv2.equalizeHist(img_noisy)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_noisy, cmap='gray')\n",
    "plt.title('Noisy Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_noisy_clahe, cmap='gray')\n",
    "plt.title('CLAHE (less noise amplification)')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_noisy_global, cmap='gray')\n",
    "plt.title('Global Equalization (more noise)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When CLAHE Shines\n",
    "\n",
    "Better than global equalization for images with varying contrast. Useful in medical imaging, aerial photos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Gamma Correction\n",
    "\n",
    "## What is Gamma Correction?\n",
    "\n",
    "Non-linear intensity adjustment. Formula: `new = old ^ (1/gamma)`\n",
    "\n",
    "Corrects for display/monitor characteristics.\n",
    "\n",
    "## Understanding Gamma Values\n",
    "\n",
    "- Gamma < 1: Brightens image (expands dark areas).\n",
    "- Gamma > 1: Darkens image (compresses bright areas).\n",
    "\n",
    "Analogy: \"Like adjusting the curve of a tone mapping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing Gamma Correction\n",
    "\n",
    "# Gamma correction function\n",
    "def gamma_correction(img, gamma):\n",
    "    img_float = img.astype(np.float32) / 255.0\n",
    "    corrected = np.power(img_float, 1/gamma)\n",
    "    return (corrected * 255).astype(np.uint8)\n",
    "\n",
    "# Example with dark image\n",
    "img_dark = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "gamma_05 = gamma_correction(img_dark, 0.5)\n",
    "gamma_22 = gamma_correction(img_dark, 2.2)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_dark, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(gamma_05, cmap='gray')\n",
    "plt.title('Gamma = 0.5 (Brighter)')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(gamma_22, cmap='gray')\n",
    "plt.title('Gamma = 2.2 (Darker)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot gamma curves\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, np.power(x, 1/0.5), label='Gamma = 0.5')\n",
    "plt.plot(x, np.power(x, 1/1.0), label='Gamma = 1.0 (Linear)')\n",
    "plt.plot(x, np.power(x, 1/2.2), label='Gamma = 2.2')\n",
    "plt.xlabel('Input Intensity')\n",
    "plt.ylabel('Output Intensity')\n",
    "plt.title('Gamma Correction Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Applications\n",
    "\n",
    "Monitor calibration, HDR imaging, photography.\n",
    "\n",
    "Common Mistake: \"Confusing gamma with linear brightness adjustment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.  Putting It All Together\n",
    "\n",
    "## Comparison of Techniques\n",
    "\n",
    "| Technique | When to Use | Pros | Cons |\n",
    "|-----------|-------------|------|------|\n",
    "| Brightness Adjustment | Simple lighting correction | Fast, intuitive | May not improve contrast |\n",
    "| Contrast Adjustment | Improve visibility | Quick enhancement | Can clip values |\n",
    "| Histogram Equalization | Low contrast images | Automatic, spreads intensities | Can amplify noise |\n",
    "| CLAHE | Varying contrast, noisy images | Local adaptation, noise control | More parameters to tune |\n",
    "| Gamma Correction | Display correction, non-linear adjustments | Preserves color ratios | Not always intuitive |\n",
    "\n",
    "## Best Practices and Tips\n",
    "\n",
    "- Always work on copies of images.\n",
    "- Experiment with parameters.\n",
    "- Consider image characteristics before choosing technique.\n",
    "- Interactive section: Let user try on their own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison on same image\n",
    "img = cv2.imread('datasets/sample_images/sample2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply different techniques\n",
    "bright = cv2.add(img, 50)\n",
    "contrast = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "equalized = cv2.equalizeHist(img)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "clahe_img = clahe.apply(img)\n",
    "gamma_img = gamma_correction(img, 0.7)\n",
    "\n",
    "# Display side-by-side\n",
    "techniques = ['Original', 'Bright +50', 'Contrast x1.5', 'Equalized', 'CLAHE', 'Gamma 0.7']\n",
    "images = [img, bright, contrast, equalized, clahe_img, gamma_img]\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, (tech, im) in enumerate(zip(techniques, images)):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.title(tech)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading and Exercises\n",
    "\n",
    "- Gonzalez & Woods: Digital Image Processing\n",
    "- OpenCV documentation\n",
    "- scikit-image tutorials\n",
    "\n",
    "Exercises:\n",
    "1. Apply brightness adjustment to different images and note the effects.\n",
    "2. Experiment with CLAHE parameters on noisy images.\n",
    "3. Implement gamma correction from scratch.\n",
    "4. Compare HSV vs YCbCr equalization on color images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Conclusion\n",
    "\n",
    "We've covered pointwise operations, histograms, equalization techniques, CLAHE, and gamma correction - essential tools for image enhancement.\n",
    "\n",
    "Key concepts recap:\n",
    "- Pointwise operations modify pixels independently\n",
    "- Histograms reveal intensity distributions\n",
    "- Equalization spreads intensities for better contrast\n",
    "- CLAHE provides adaptive, noise-controlled enhancement\n",
    "- Gamma correction handles non-linear adjustments\n",
    "\n",
    "Encourage experimentation and exploration of next topics like filtering and feature detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
