{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbf758c",
   "metadata": {},
   "source": [
    "# Module 1 — Supervised Learning\n",
    "\n",
    "**Created:** 2025-12-04 14:06:54 UTC\n",
    "\n",
    "## Overview\n",
    "\n",
    "Supervised learning is a machine learning paradigm where we train a model using labeled data—data that includes both input features and known output labels (targets). The goal is to learn a mapping from inputs to outputs so that the model can predict outcomes for new, unseen data. This is analogous to learning with a teacher who provides correct answers.\n",
    "\n",
    "### Why Supervised Learning?\n",
    "Supervised learning is used when we have access to labeled data and want to predict specific outcomes. Unlike unsupervised learning, where patterns are discovered from unlabeled data, supervised learning focuses on prediction tasks where we know what the \"correct\" answers are (e.g., email is spam or not, patient's diagnosis).\n",
    "\n",
    "### Where It's Applied\n",
    "- **Classification:** Predicting categorical labels.\n",
    "  - Spam detection (classify emails as spam or not).\n",
    "  - Medical diagnosis (classify tumors as benign or malignant).\n",
    "  - Sentiment analysis (classify text as positive or negative).\n",
    "- **Regression:** Predicting continuous numerical values.\n",
    "  - House price prediction (predict price based on features like size, location).\n",
    "  - Sales forecasting (predict sales volume based on historical data).\n",
    "  - Stock price prediction.\n",
    "\n",
    "### When to Choose Supervised Learning\n",
    "Choose supervised learning when:\n",
    "- Labeled data is available (or can be obtained).\n",
    "- The task is to map inputs to known outputs (prediction-oriented).\n",
    "- You need interpretable and accurate predictions for decision-making.\n",
    "- Examples: When building recommendation systems, fraud detection, or automated grading, where historical labeled examples exist.\n",
    "\n",
    "## Learning objectives\n",
    "- Understand the difference between classification and regression.\n",
    "- Learn a simple beginner example using scikit-learn.\n",
    "- Step up to intermediate model selection and evaluation.\n",
    "- See advanced notes on bias-variance, regularization, and example with pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5ee52",
   "metadata": {},
   "source": [
    "## Beginner — Concept + Simple Example\n",
    "\n",
    "**Concept (2 sentences):** In supervised learning you provide examples (features) and labels (targets). The model learns a mapping so you can predict labels for new data.\n",
    "\n",
    "**Simple code:** We'll load the Iris dataset and train a small decision tree classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginner example (do not run here — included for learners)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, preds))\n",
    "\n",
    "# Explanation:\n",
    "# - load_iris(): small labeled dataset for classification\n",
    "# - DecisionTreeClassifier: easy-to-visualize model\n",
    "# - We split into train/test and compute accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219de0cc",
   "metadata": {},
   "source": [
    "## Intermediate — Model selection & evaluation\n",
    "\n",
    "**What to learn:** Cross-validation, hyperparameter tuning, precision/recall, confusion matrix.\n",
    "\n",
    "**Code idea:** Use `GridSearchCV` to tune an SVM and evaluate with cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate example (runnable on your machine)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "param_grid = {'svc__C':[0.1,1,10], 'svc__kernel':['rbf','linear']}\n",
    "search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "search.fit(X, y)\n",
    "print('Best params:', search.best_params_)\n",
    "print('Best CV score:', search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc54f14",
   "metadata": {},
   "source": [
    "## Advanced — Theory and pipeline example\n",
    "\n",
    "**Topics:** Bias vs variance, regularization, learning curves, feature engineering, pipelines for reproducible workflows.\n",
    "\n",
    "**Advanced code sketch:** Example showing a pipeline with feature selection and regularized model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44543b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced example (sketch)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('select', SelectKBest(f_classif, k=2)),\n",
    "    ('clf', LogisticRegression(penalty='l2', C=1.0, max_iter=1000))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Train score:', pipeline.score(X_train, y_train))\n",
    "print('Test score:', pipeline.score(X_test, y_test))\n",
    "\n",
    "# Final notes:\n",
    "# - Regularization (penalty, C) controls overfitting\n",
    "# - Use learning curves (sklearn.model_selection.learning_curve) to diagnose\n"
   ]
  }
 ],
 "metadata": {
  "title": "Module 1 — Supervised Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
