{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32f1719",
   "metadata": {},
   "source": [
    "# Capstone Projects — Paradigms of Machine Learning\n",
    "\n",
    "**Created:** 2025-12-04 14:21:45 UTC\n",
    "\n",
    "This notebook lists 6 capstone projects (project brief, dataset suggestions, success criteria, milestones, and starter code snippets). Each project can be expanded into a full course-length assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bf260",
   "metadata": {},
   "source": [
    "## Project A — End-to-end Image Classification Pipeline\n",
    "\n",
    "**Brief:** Build a production-ready image classification pipeline: data ingestion, augmentation, training, validation, model serving.\n",
    "\n",
    "**Dataset suggestions:** CIFAR-10/CIFAR-100, Caltech-101, custom dataset.\n",
    "\n",
    "**Milestones:**\n",
    "1. EDA and preprocessing\n",
    "2. Baseline CNN training\n",
    "3. Transfer learning and hyperparameter tuning\n",
    "4. Model interpretation and calibration\n",
    "5. Export model and simple REST API for inference\n",
    "\n",
    "**Success criteria:** >85% on CIFAR-10 or robust performance on custom dataset; reproducible training logs and deployment demo.\n",
    "\n",
    "**Starter snippet (training loop):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc66735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter snippet: training loop (reuse the CNN training loop from advanced notebook)\n",
    "# Save model, evaluation metrics, and a small Flask app to serve predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd393f",
   "metadata": {},
   "source": [
    "## Project B — Sentiment Analysis with Transformers\n",
    "\n",
    "**Brief:** Fine-tune a transformer for sentiment analysis, add explainability, and optimize for latency.\n",
    "\n",
    "**Dataset suggestions:** IMDb, SST-2, or custom reviews dataset.\n",
    "\n",
    "**Milestones:**\n",
    "1. Data cleaning and tokenizer experiments\n",
    "2. Baseline with DistilBERT/bert-base\n",
    "3. Distillation or quantization for faster inference\n",
    "4. Explainability with LIME/SHAP\n",
    "5. Deployment as serverless endpoint\n",
    "\n",
    "**Starter snippet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf80b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face fine-tuning snippet (see advanced notebook for full example)\n",
    "# Use Trainer API, then export to ONNX and run inference with optimized runtime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf459b9a",
   "metadata": {},
   "source": [
    "## Project C — Time-series Anomaly Detection\n",
    "\n",
    "**Brief:** Detect anomalies in IoT/time-series data using deep learning (autoencoders, LSTMs, or Transformers). This project covers the entire pipeline from data preprocessing to deployment.\n",
    "\n",
    "### Why/When to Use Anomaly Detection\n",
    "Anomaly detection is used when you need to identify rare events or outliers in data that deviate significantly from the norm. It's unsupervised in most cases, meaning you don't have labeled anomaly data.\n",
    "\n",
    "- **When to use:** For monitoring systems like IoT sensors, financial transactions, network traffic, or industrial equipment where anomalies indicate faults, fraud, or security breaches.\n",
    "- **Challenges:** Imbalanced data (anomalies are rare), need for real-time processing, and distinguishing true anomalies from noise.\n",
    "\n",
    "### Real-World Applications\n",
    "- **Industrial IoT:** Detecting equipment failures in manufacturing (e.g., predictive maintenance).\n",
    "- **Cybersecurity:** Identifying unusual network patterns or intrusions.\n",
    "- **Finance:** Fraud detection in credit card transactions or stock market anomalies.\n",
    "- **Healthcare:** Monitoring patient vitals for abnormal readings indicating medical issues.\n",
    "- **Energy:** Detecting leaks or inefficiencies in power grids.\n",
    "\n",
    "**Brief:** Detect anomalies in IoT/time-series data using deep learning (autoencoders, LSTMs, or Transformers).\n",
    "\n",
    "**Dataset suggestions:** NAB, NASA bearing datasets, or your own telemetry.\n",
    "\n",
    "**Milestones:**\n",
    "1. Preprocessing and windowing\n",
    "2. Baseline statistical methods\n",
    "3. Autoencoder / seq2seq model\n",
    "4. Real-time scoring pipeline\n",
    "\n",
    "**Starter snippet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder sketch (PyTorch)\n",
    "import torch.nn as nn\n",
    "class SeqAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim//2))\n",
    "        self.decoder = nn.Sequential(nn.Linear(hidden_dim//2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, input_dim))\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e64fdd",
   "metadata": {},
   "source": [
    "## Project D — Generative Modeling (GANs / Diffusion Models)\n",
    "\n",
    "**Brief:** Train a generative model to produce images; compare GANs vs diffusion models.\n",
    "\n",
    "**Dataset suggestions:** CelebA, LSUN, or a focused dataset.\n",
    "\n",
    "**Milestones:**\n",
    "1. Implement DCGAN baseline\n",
    "2. Add training stabilization and evaluation (FID)\n",
    "3. Explore diffusion model baseline (if compute allows)\n",
    "\n",
    "**Starter snippet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8082c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use existing libraries for diffusion (e.g., diffusers) or implement DCGAN sketch from advanced notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8058eb",
   "metadata": {},
   "source": [
    "## Project E — Reinforcement Learning for a Simulated Control Task\n",
    "\n",
    "**Brief:** Train an agent in a simulated environment (robotics, finance simulator, or custom Gym env).\n",
    "\n",
    "**Dataset / env:** OpenAI Gym environments, MuJoCo (if licensed), or PyBullet.\n",
    "\n",
    "**Milestones:**\n",
    "1. Implement baseline (DQN / PPO)\n",
    "2. Hyperparameter search and evaluation\n",
    "3. Integrate curriculum learning or domain randomization\n",
    "\n",
    "**Starter snippet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97845528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using stable-baselines3 (see advanced notebook)\n",
    "# from stable_baselines3 import PPO\n",
    "# env = gym.make('LunarLander-v2')\n",
    "# model = PPO('MlpPolicy', env, verbose=1)\n",
    "# model.learn(total_timesteps=200000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6842c12",
   "metadata": {},
   "source": [
    "## Project F — Few-shot Learning & Meta-learning\n",
    "\n",
    "**Brief:** Implement a prototypical network or MAML for few-shot classification and evaluate on mini-ImageNet/Omniglot.\n",
    "\n",
    "**Milestones:**\n",
    "1. Implement episodic training loop\n",
    "2. Build prototypical network baseline\n",
    "3. Evaluate N-way K-shot tasks\n",
    "\n",
    "**Starter snippet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototypical network sketch (concept)\n",
    "# - Build encoder (ConvNet)\n",
    "# - For each episode: sample support and query sets, compute prototypes, compute distances, update encoder with cross-entropy loss.\n"
   ]
  }
 ],
 "metadata": {
  "title": "Capstone Projects — Paradigms of ML"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
