{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ecad698",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Examples\n",
    "\n",
    "**Created:** 2025-12-04 14:21:45 UTC\n",
    "\n",
    "This notebook collects advanced, practical deep-learning examples with clear explanations, full training loops, and tips for reproducible experiments. Each section is a self-contained example you can run locally. Requirements (commonly): `torch`, `torchvision`, `transformers`, `datasets`, `accelerate`, `tqdm`, `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d661f3f",
   "metadata": {},
   "source": [
    "## 1) CNN Image Classification — Full PyTorch Training Loop\n",
    "\n",
    "Goal: Train a ResNet18 on CIFAR-10 (or a small custom dataset). This section shows data loading, augmentation, model, training loop with checkpointing, mixed precision, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Image Classification - PyTorch (runnable)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = './data/cifar10'\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "lr = 1e-3\n",
    "checkpoint_dir = './checkpoints/cnn_cifar10'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.247,0.243,0.261))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.247,0.243,0.261))\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "test_ds = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Model (pretrained backbone, small head)\n",
    "model = models.resnet18(pretrained=False, num_classes=10)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader, desc='Train', leave=False)\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device); targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if scaler:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += images.size(0)\n",
    "        pbar.set_postfix(loss=running_loss/total, acc=100*correct/total)\n",
    "    return running_loss/total, 100*correct/total\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0; total = 0; loss_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device); targets = targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss_sum += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += images.size(0)\n",
    "    return loss_sum/total, 100*correct/total\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, device)\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch}: train_loss={train_loss:.4f}, train_acc={train_acc:.2f}%, val_loss={val_loss:.4f}, val_acc={val_acc:.2f}%')\n",
    "    # checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'optimizer_state': optimizer.state_dict()}, os.path.join(checkpoint_dir, 'best.pth'))\n",
    "print('Training complete. Best val acc:', best_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376c041",
   "metadata": {},
   "source": [
    "## 2) Transfer Learning — Fine-tuning a Pretrained CNN\n",
    "\n",
    "Goal: Use a pretrained ImageNet model, replace the head and fine-tune for a new dataset. Tips: frozen backbone, staged unfreezing, differential learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9951b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning sketch (PyTorch)\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "# Replace final layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 5)  # e.g., 5 classes on new dataset\n",
    "# Freeze backbone\n",
    "for name, param in model.named_parameters():\n",
    "    if 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "# Train head first, then unfreeze some layers and fine-tune with smaller LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d0b91",
   "metadata": {},
   "source": [
    "## 3) Transformers for NLP — Fine-tuning BERT with Hugging Face\n",
    "\n",
    "Goal: Fine-tune a pretrained transformer (BERT) for sequence classification using `transformers` + `datasets`. Uses Trainer API for brevity and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43730979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers fine-tuning (using Hugging Face Trainer)\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "dataset = load_dataset('glue', 'mrpc')  # example\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch['sentence1'], batch['sentence2'], truncation=True, padding='max_length', max_length=128)\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "dataset = dataset.rename_column('label', 'labels')\n",
    "dataset.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "args = TrainingArguments(output_dir='./results', evaluation_strategy='epoch', per_device_train_batch_size=16, num_train_epochs=3, save_total_limit=2)\n",
    "trainer = Trainer(model=model, args=args, train_dataset=dataset['train'], eval_dataset=dataset['validation'])\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c78435",
   "metadata": {},
   "source": [
    "## 4) Generative Adversarial Networks (GANs) — Basic DCGAN Sketch\n",
    "\n",
    "Goal: Understand generator/discriminator training alternating steps and stabilization tips (batchnorm, label smoothing, spectral norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN simplified sketch (PyTorch)\n",
    "# This is a condensed sketch; for full training follow dcgan tutorials.\n",
    "import torch.nn as nn\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=100, ngf=64, nc=3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            # more layers...\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # more layers...\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1,1).squeeze(1)\n",
    "# Training alternates: update D on real+fake, then update G to fool D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c472ff",
   "metadata": {},
   "source": [
    "## 5) Deep Reinforcement Learning — DQN / PPO Practical Notes\n",
    "\n",
    "Goal: Use existing libraries (stable-baselines3, rl-baselines3-zoo) for reliable implementations. Included is a short sketch and tips for reproducibility and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d362e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep RL recommendation (sketch) - install stable-baselines3\n",
    "# pip install stable-baselines3[extra]\n",
    "# Example usage:\n",
    "# from stable_baselines3 import DQN\n",
    "# import gym\n",
    "# env = gym.make('CartPole-v1')\n",
    "# model = DQN('MlpPolicy', env, learning_rate=1e-3, buffer_size=50000, exploration_fraction=0.1, verbose=1)\n",
    "# model.learn(total_timesteps=100000)\n",
    "# model.save('dqn_cartpole')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b36d6",
   "metadata": {},
   "source": [
    "## Additional tips\n",
    "\n",
    "- Use deterministic seeds and document software/hardware.\n",
    "- Log with TensorBoard or Weights & Biases.\n",
    "- Profile training for bottlenecks (data loading, augmentation).\n",
    "- Use mixed precision and gradient accumulation for large-batch training on limited GPUs.\n"
   ]
  }
 ],
 "metadata": {
  "title": "Advanced Deep Learning Examples"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
